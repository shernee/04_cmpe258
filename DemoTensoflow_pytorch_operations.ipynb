{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shernee/04_cmpe258/blob/main/DemoTensoflow_pytorch_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow operations"
      ],
      "metadata": {
        "id": "iHy6ybEAQ63j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Boradcasting"
      ],
      "metadata": {
        "id": "bBWhozSzdoIL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjTch21OLoRU"
      },
      "outputs": [],
      "source": [
        "#import library\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sample data\n",
        "sample_data = tf.constant([4,5,6,7])\n",
        "print(\"This is a Sample data:\",sample_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1FoYVGlRChq",
        "outputId": "2610ddf7-e86e-4970-f21d-db37014c46b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Sample data: tf.Tensor([4 5 6 7], shape=(4,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#broadcast sample data\n",
        "broadcast_data = tf.broadcast_to(sample_data, [4,4])\n",
        "print(\"This is the data after broadcasting:\",broadcast_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyGKWUIWRS0k",
        "outputId": "ed471dca-4bfe-465c-d3ad-0017b6bc5f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the data after broadcasting: tf.Tensor(\n",
            "[[4 5 6 7]\n",
            " [4 5 6 7]\n",
            " [4 5 6 7]\n",
            " [4 5 6 7]], shape=(4, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor with float values\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "print(rank_1_tensor)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H8Eb-6JRarb",
        "outputId": "82f0619c-d17e-434d-b6f6-b934265b5103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor with three axis\n",
        "rank_2_tensor = tf.constant([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "\n",
        "print(rank_2_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n78u2BG5UkBC",
        "outputId": "eeecfbea-8e17-4d6d-d0ec-5d26c8fed985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting tensor to numpy\n",
        "np.array(rank_2_tensor)\n",
        "rank_2_tensor.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvVaEYksU254",
        "outputId": "433d3f73-c904-4837-cb70-127a8291c777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0,  1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8,  9]],\n",
              "\n",
              "       [[10, 11, 12, 13, 14],\n",
              "        [15, 16, 17, 18, 19]],\n",
              "\n",
              "       [[20, 21, 22, 23, 24],\n",
              "        [25, 26, 27, 28, 29]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them.\n",
        "#The simplest and most common case is when you attempt to multiply or add a tensor to a scalar. In that case, the scalar is broadcast to be the same shape as the other argument.\n",
        "x = tf.constant([1, 2, 3])\n",
        "\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2, 2, 2])\n",
        "# All of these are the same computation\n",
        "print(tf.multiply(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVoRZDp1Rz-I",
        "outputId": "dfcf262c-98cd-401a-d81d-7198a3eade6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#same operations without broadcasting\n",
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm4--sU-R13r",
        "outputId": "4fb7b7bb-2dda-4786-dfe0-6933a42c6598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Most of the time, broadcasting is both time and space efficient, as the broadcast operation never materializes the expanded tensors in memory.\n",
        "#You see what broadcasting looks like using tf.broadcast_to\n",
        "\n",
        "print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQfjWiC_YSj7",
        "outputId": "cd25aefd-7be4-4aee-b447-7f6729b9428b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]], shape=(3, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ragged Tensors"
      ],
      "metadata": {
        "id": "LCauH1wZYrx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A tensor with variable numbers of elements along some axis is called \"ragged\". Use tf.ragged.RaggedTensor for ragged data.\n",
        "#For example, This cannot be represented as a regular tensor\n",
        "\n",
        "ragged_list = [\n",
        "    [0, 1, 2, 3],\n",
        "    [4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9]]\n",
        "\n",
        "ragged_tensor = tf.ragged.constant(ragged_list)\n",
        "print(ragged_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD4NlnfHYgrU",
        "outputId": "820f1dd4-0602-45bb-ab1a-72e6e21438a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ragged_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dq6MZaCZkHc",
        "outputId": "1c28949b-ef47-44d5-b6e9-07af5e496451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sparse tensors"
      ],
      "metadata": {
        "id": "UXc7L3miYzyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sometimes, your data is sparse, like a very wide embedding space. TensorFlow supports tf.sparse.SparseTensor and related operations to store sparse data efficiently.\n",
        "# Sparse tensors store values by index in a memory-efficient manner\n",
        "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
        "                                       values=[1, 2],\n",
        "                                       dense_shape=[3, 4])\n",
        "print(sparse_tensor, \"\\n\")\n",
        "\n",
        "# You can convert sparse tensors to dense\n",
        "print(tf.sparse.to_dense(sparse_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSKJvaCXY09f",
        "outputId": "73ae3454-f315-4316-f7c6-855a0d74ce93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0]\n",
            " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 0 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sc7eIhSKbHje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#String tensors"
      ],
      "metadata": {
        "id": "biGkcD25Y1Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The strings are atomic and cannot be indexed the way Python strings are. The length of the string is not one of the axes of the tensor\n",
        "#scalar string tensor\n",
        "scalar_string_tensor = tf.constant(\"Gray wolf\")\n",
        "print(scalar_string_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhFYyNsNY6w1",
        "outputId": "fbcc4b15-abaf-492f-9c0e-10df6971e39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Gray wolf', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
        "                                 \"Quick brown fox\",\n",
        "                                 \"Lazy dog\"])\n",
        "# Note that the shape is (3,). The string length is not included.\n",
        "print(tensor_of_strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0TZIFZSaEWu",
        "outputId": "4230bca7-d59b-432e-bee1-030595fffb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can use split to split a string into a set of tensors\n",
        "print(tf.strings.split(scalar_string_tensor, sep=\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esA7--_qaF8z",
        "outputId": "ea2afb4d-9f8b-466a-93b1-f34e269084f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.strings.split(tensor_of_strings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vneb9Fe4aOvB",
        "outputId": "d1fd8881-95af-4247-bc09-09990c58fb13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert string to a number\n",
        "text = tf.constant(\"1 10 100\")\n",
        "print(tf.strings.to_number(tf.strings.split(text, \" \")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHP5SQPTaSi3",
        "outputId": "a73afae4-c2de-48a3-d527-7efcd2484399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting string to bytes and then to numbers\n",
        "byte_strings = tf.strings.bytes_split(tf.constant(\"Duck\"))\n",
        "byte_ints = tf.io.decode_raw(tf.constant(\"Duck\"), tf.uint8)\n",
        "print(\"Byte strings:\", byte_strings)\n",
        "print(\"Bytes:\", byte_ints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdVzFCSaamaY",
        "outputId": "73047d8e-219e-4418-f6b4-75bcec6e7731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)\n",
            "Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting strings as unicode and then decode it\n",
        "unicode_bytes = tf.constant(\"ã‚¢ãƒ’ãƒ« ðŸ¦†\")\n",
        "unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, \"UTF-8\")\n",
        "unicode_values = tf.strings.unicode_decode(unicode_bytes, \"UTF-8\")\n",
        "\n",
        "print(\"\\nUnicode bytes:\", unicode_bytes)\n",
        "print(\"\\nUnicode chars:\", unicode_char_bytes)\n",
        "print(\"\\nUnicode values:\", unicode_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5Oafjd-a1EI",
        "outputId": "1a5f55bf-514a-4024-8882-210a0175f986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unicode bytes: tf.Tensor(b'\\xe3\\x82\\xa2\\xe3\\x83\\x92\\xe3\\x83\\xab \\xf0\\x9f\\xa6\\x86', shape=(), dtype=string)\n",
            "\n",
            "Unicode chars: tf.Tensor([b'\\xe3\\x82\\xa2' b'\\xe3\\x83\\x92' b'\\xe3\\x83\\xab' b' ' b'\\xf0\\x9f\\xa6\\x86'], shape=(5,), dtype=string)\n",
            "\n",
            "Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Named tensors"
      ],
      "metadata": {
        "id": "LUhtYUz0Y7Mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "my_variable = tf.Variable(my_tensor)\n",
        "\n",
        "# Variables can be all kinds of types, just like tensors\n",
        "bool_variable = tf.Variable([False, False, False, True])\n",
        "complex_variable = tf.Variable([5 + 4j, 6 + 1j])\n",
        "# Create a and b; they will have the same name but will be backed by\n",
        "# different tensors.\n",
        "a = tf.Variable(my_tensor, name=\"Mark\")\n",
        "# A new variable with the same name, but different value\n",
        "# Note that the scalar add is broadcast\n",
        "b = tf.Variable(my_tensor + 1, name=\"Mark\")\n",
        "\n",
        "# These are elementwise-unequal, despite having the same name\n",
        "print(a == b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW2o0bayZG-F",
        "outputId": "74f3f3a2-3d70-4cce-ce2c-2c81034c3b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[False False]\n",
            " [False False]], shape=(2, 2), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Operations in Pytorch"
      ],
      "metadata": {
        "id": "GARAnJNOdcsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Broadcasting"
      ],
      "metadata": {
        "id": "3CGYk6GIdggb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ZcREbdgjgbHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([[1, 2], [0, 3]])\n",
        "tensor2 = torch.tensor([[3, 1]])\n",
        "tensor3 = torch.tensor([[5], [2]])\n",
        "tensor4 = torch.tensor([7])\n",
        "\n",
        "print(tensor1.shape)\n",
        "# Outputs- torch.Size([2, 2])\n",
        "print(tensor2.shape)\n",
        "# Outputs- torch.Size([1, 2])\n",
        "print(tensor3.shape)\n",
        "# Outputs- torch.Size([2, 1])\n",
        "print(tensor4.shape)\n",
        "# Outputs- torch.Size([1])\n",
        "\n",
        "print(tensor1 + tensor2)\n",
        "# Outputs- tensor([[4, 3], [3, 4]])\n",
        "print(tensor1 + tensor3)\n",
        "# Outputs- tensor([[6, 7], [2, 5]])\n",
        "print(tensor2 + tensor3)\n",
        "# Outputs- tensor([[8, 6], [5, 3]])\n",
        "print(tensor1 + tensor4)\n",
        "# Outputs- tensor([[ 8, 9], [ 7, 10]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaFl9HeCgPFh",
        "outputId": "1bde2b64-b0e4-462d-8c16-29b76e6798b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([1, 2])\n",
            "torch.Size([2, 1])\n",
            "torch.Size([1])\n",
            "tensor([[4, 3],\n",
            "        [3, 4]])\n",
            "tensor([[6, 7],\n",
            "        [2, 5]])\n",
            "tensor([[8, 6],\n",
            "        [5, 3]])\n",
            "tensor([[ 8,  9],\n",
            "        [ 7, 10]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ragged Tensors - Nested tensors"
      ],
      "metadata": {
        "id": "GAFFG09sgjRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(20, 128) # text 1\n",
        "nt = torch.nested.nested_tensor([a, a], dtype=torch.float32)\n",
        "nt.size(0)\n",
        "2\n",
        "nt.size(1)\n",
        "20\n",
        "nt.size(2)\n",
        "128\n",
        "torch.stack(nt.unbind()).size()\n",
        "torch.Size([2, 20, 128])\n",
        "torch.stack([a, a]).size()\n",
        "torch.Size([2, 20, 128])\n",
        "torch.equal(torch.stack(nt.unbind()), torch.stack([a, a]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-4TEc8mge_t",
        "outputId": "5e8f8293-d230-43f3-b479-353cca9ed150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nested/__init__.py:47: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:175.)\n",
            "  nt = torch._nested_tensor_from_tensor_list(new_data, dtype, None, device, pin_memory)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sparse Tensors"
      ],
      "metadata": {
        "id": "zsWhSwhshL4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[0, 2.], [3, 0]])\n",
        "a.to_sparse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpW8ezDfhGdI",
        "outputId": "d07fd480-dcaf-45a2-9783-314cbe767e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(indices=tensor([[0, 1],\n",
              "                       [1, 0]]),\n",
              "       values=tensor([2., 3.]),\n",
              "       size=(2, 2), nnz=2, layout=torch.sparse_coo)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[[1., 0], [2., 3.]], [[4., 0], [5., 6.]]])\n",
        "t.dim()\n",
        "t.to_sparse_csr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajeO3kXZhSjm",
        "outputId": "8eb110aa-509d-4d45-be65-fe32ecf52659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-75483179f322>:3: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
            "  t.to_sparse_csr()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(crow_indices=tensor([[0, 1, 3],\n",
              "                            [0, 1, 3]]),\n",
              "       col_indices=tensor([[0, 0, 1],\n",
              "                           [0, 0, 1]]),\n",
              "       values=tensor([[1., 2., 3.],\n",
              "                      [4., 5., 6.]]), size=(2, 2, 2), nnz=3,\n",
              "       layout=torch.sparse_csr)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Named tensors"
      ],
      "metadata": {
        "id": "H1MCqnmkhyud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Factory functions take a new names argument that associates a name with each dimension.\n",
        "torch.zeros(2, 3, names=('N', 'C'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRZ5X5-thc1K",
        "outputId": "01ddf918-00d6-4299-8f02-c42ffc661054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-09d92866311e>:2: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)\n",
            "  torch.zeros(2, 3, names=('N', 'C'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]], names=('N', 'C'))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = torch.randn(1, 2, 2, 3 , names=('N', 'C', 'H', 'W'))\n",
        "imgs.names\n",
        "renamed_imgs = imgs.rename(H='height', W='width')\n",
        "renamed_imgs.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AljcWoyth-m4",
        "outputId": "8e3fea0b-067e-4ff2-d1c2-5fce4c9dfa73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('N', 'C', 'height', 'width')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, names=('X',))\n",
        "y = torch.randn(3)\n",
        "z = torch.randn(3, names=('Z',))"
      ],
      "metadata": {
        "id": "mQFXXnPBiGsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x + y).names\n",
        "(x + x).names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWp3RjNOiNpI",
        "outputId": "e34d8e7b-a6d0-4ea4-8fca-404589be8aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('X',)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#String tensors"
      ],
      "metadata": {
        "id": "yGtejwmLidDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#There is no string tensor so you cannot directly convert to pytorch tensor of strings.\n",
        "#Alternative, you can convert the string to ASCII char values and save that as a Tensor\n",
        "#or use scikit to encode strings and convert to tensors\n",
        "from sklearn import preprocessing\n",
        "labels = ['cat', 'dog', 'mouse', 'elephant', 'pandas']\n",
        "le = preprocessing.LabelEncoder()\n",
        "targets = le.fit_transform(labels)\n",
        "targets = torch.as_tensor(targets)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OORD_PtQifsm",
        "outputId": "2cbb5469-c73c-46e5-da71-f3d548e9b7f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 3, 2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement linear search using tensor flow"
      ],
      "metadata": {
        "id": "CHwScjDLkBoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "# import tensorflow.compat.v1 as tf\n",
        "import tensorflow._api.v2.compat.v1 as v1\n",
        "v1.disable_v2_behavior()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class LinearSearch():\n",
        "    def __init__(self, array, x):\n",
        "        self.x = tf.constant(x)\n",
        "        self.array = tf.constant(array)\n",
        "        self.length = len(array)\n",
        "        self.graph = tf.while_loop(self.cond, self.body, [0, self.x, False],\n",
        "                            back_prop=False)\n",
        "\n",
        "    def run(self):\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "            tf.compat.v1.disable_eager_execution()\n",
        "            tf.compat.v1.global_variables_initializer().run()\n",
        "            return sess.run(self.graph)\n",
        "\n",
        "    def cond(self, i, _, is_found):\n",
        "        return tf.logical_and(tf.less(i, self.length), tf.logical_not(is_found))\n",
        "\n",
        "    def body(self, i, _, is_found):\n",
        "        return tf.cond(tf.equal(self.array[i], self.x),\n",
        "                    lambda: (i, self.array[i], True),\n",
        "                    lambda: (tf.add(i, 1), -1, False))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    array, x = [20, 70, 33, 84], 33\n",
        "    search = LinearSearch(array, x)\n",
        "    ix, xx, is_found = ret = search.run()\n",
        "    print('Array :', array)\n",
        "    print('Number to search :', x)\n",
        "    if is_found:\n",
        "        print('{} is at index {}.'.format(xx, ix))\n",
        "    else:\n",
        "        print('Not found.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxiCyWw8kQwR",
        "outputId": "9e1fecba-8a31-41fb-b4a1-8128afdac42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array : [20, 70, 33, 84]\n",
            "Number to search : 33\n",
            "33 is at index 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement Binary search using tensor flow"
      ],
      "metadata": {
        "id": "iNIQ3DL4k3zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "# import tensorflow.compat.v1 as tf\n",
        "import tensorflow._api.v2.compat.v1 as v1\n",
        "v1.disable_v2_behavior()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class BinarySearch():\n",
        "    def __init__(self, array, x):\n",
        "        self.array = tf.constant(array)\n",
        "        self.x = tf.constant(x)\n",
        "        self.loop = tf.while_loop(self.cond, self.body, [-1,False,0,len(array),-1],\n",
        "                        back_prop=False)\n",
        "\n",
        "    def run(self):\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "            tf.compat.v1.disable_eager_execution()\n",
        "            tf.compat.v1.global_variables_initializer().run()\n",
        "            return sess.run(self.loop)\n",
        "\n",
        "    def cond(self, x, is_found, left, right, mid):\n",
        "        return tf.logical_and(tf.less_equal(left, right), tf.logical_not(is_found))\n",
        "\n",
        "    def body(self, x, is_found, left, right, mid):\n",
        "        mid = tf.cast(tf.divide(tf.add(left, right), 2),tf.int32)\n",
        "        return tf.cond(tf.equal(self.array[mid], self.x),\n",
        "                    lambda: (self.array[mid], True, left, right, mid),\n",
        "                    lambda: tf.cond(tf.less(self.array[mid], self.x),\n",
        "                                lambda: (-1, False, tf.add(mid, 1), right, mid),\n",
        "                                lambda: (-1, False, left, tf.subtract(mid, 1), mid)))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    array = sorted([10, 30, 52, 74, 84])\n",
        "    x = 52\n",
        "    search = BinarySearch(array, x)\n",
        "    xx, is_found, l, r, m = search.run()\n",
        "\n",
        "    print('Array :', array)\n",
        "    print('Number to search :', x)\n",
        "    if is_found:\n",
        "        print('{} is at index {}.'.format(xx, m))\n",
        "    else:\n",
        "        print('Not found.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sut7lqD4k79K",
        "outputId": "63cdaaa5-26cd-4e3b-e454-9cffd0a0b64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array : [10, 30, 52, 74, 84]\n",
            "Number to search : 52\n",
            "52 is at index 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Insertion sort using tensor flow"
      ],
      "metadata": {
        "id": "TF11_GGEpulr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow._api.v2.compat.v1 as v1\n",
        "v1.disable_v2_behavior()\n",
        "np.random.seed(123)\n",
        "\n",
        "\n",
        "class InsertionSort():\n",
        "    def __init__(self, array):\n",
        "        self.i = tf.constant(1)\n",
        "        self.j = tf.constant(len(array)-1)\n",
        "        self.array = tf.Variable(array, trainable=False)\n",
        "        self.length = len(array)\n",
        "\n",
        "        cond = lambda i, j, _: tf.less(i-1, self.length-1)\n",
        "        self.graph = tf.while_loop(cond, self.outer_loop, loop_vars=[self.i, self.j, self.array],\n",
        "                shape_invariants=[self.i.get_shape(), self.j.get_shape(), tf.TensorShape(self.length)],\n",
        "                parallel_iterations=1,\n",
        "                back_prop=False)\n",
        "\n",
        "    def run(self):\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "            tf.compat.v1.disable_eager_execution()\n",
        "            tf.compat.v1.global_variables_initializer().run()\n",
        "            return sess.run(self.graph)\n",
        "\n",
        "    def outer_loop(self, i, j, _):\n",
        "        j = i\n",
        "        cond = lambda i, j, array: tf.logical_and(tf.greater(j,0), tf.greater(array[j-1], array[j]))\n",
        "\n",
        "        loop = tf.while_loop(cond, self.inner_loop, loop_vars=[i, j, self.array],\n",
        "                    shape_invariants=[i.get_shape(), j.get_shape(), tf.TensorShape(self.length)],\n",
        "                    parallel_iterations=1,\n",
        "                    back_prop=False)\n",
        "        return tf.add(i, 1), loop[1], loop[2]\n",
        "\n",
        "    def inner_loop(self, i, j, _):\n",
        "        return i, tf.subtract(j, 1), tf.compat.v1.scatter_nd_update(self.array, [[j-1],[j]], [self.array[j],self.array[j-1]])\n",
        "\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    x = np.array([1.,7.,3.,8.])\n",
        "    print(x)\n",
        "    print(InsertionSort(x).run()[2])\n",
        "    y = np.random.rand(10)\n",
        "    print(y)\n",
        "    print(InsertionSort(y).run()[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrRA_xgwp08M",
        "outputId": "7e61a309-8fc9-4bc9-9c95-ccca66e7b018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 7. 3. 8.]\n",
            "[1. 3. 7. 8.]\n",
            "[0.69646919 0.28613933 0.22685145 0.55131477 0.71946897 0.42310646\n",
            " 0.9807642  0.68482974 0.4809319  0.39211752]\n",
            "[0.22685145 0.28613933 0.39211752 0.42310646 0.4809319  0.55131477\n",
            " 0.68482974 0.69646919 0.71946897 0.9807642 ]\n"
          ]
        }
      ]
    }
  ]
}