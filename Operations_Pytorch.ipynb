{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shernee/04_cmpe258/blob/main/Operations_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQjnqkIqqB9L"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar vector multiplication\n",
        "\n",
        "a = torch.rand(1)\n",
        "b = torch.rand(5, 2)\n",
        "mult = torch.einsum('i, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtFaCWo7sxjW",
        "outputId": "0a5cc90a-37d6-44a7-f731-a4c4b4abd2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5007])\n",
            "tensor([[0.5422, 0.1373],\n",
            "        [0.6885, 0.4197],\n",
            "        [0.7236, 0.2490],\n",
            "        [0.6489, 0.1423],\n",
            "        [0.9284, 0.9190]])\n",
            "tensor([[0.2715, 0.0688],\n",
            "        [0.3447, 0.2101],\n",
            "        [0.3623, 0.1247],\n",
            "        [0.3249, 0.0713],\n",
            "        [0.4648, 0.4601]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector vector multiplication\n",
        "\n",
        "a = torch.rand(3, 4)\n",
        "b = torch.rand(4, 2)\n",
        "mult = torch.einsum('ij, jk -> ik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR0oA9l5tO0a",
        "outputId": "7da0ea03-2342-4cff-9eaf-b0ceeeef378b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9670, 0.5860, 0.4055, 0.1666],\n",
            "        [0.2807, 0.7668, 0.8024, 0.5411],\n",
            "        [0.7601, 0.4636, 0.4499, 0.8677]])\n",
            "tensor([[0.8703, 0.8567],\n",
            "        [0.0394, 0.2347],\n",
            "        [0.8992, 0.9251],\n",
            "        [0.8815, 0.0520]])\n",
            "tensor([[1.3761, 1.3496],\n",
            "        [1.4730, 1.1908],\n",
            "        [1.8493, 1.2214]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer product\n",
        "\n",
        "a = torch.arange(4)\n",
        "b = torch.arange(2, 7)  \n",
        "prod = torch.einsum('i,j -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXP4fcRjuNi7",
        "outputId": "c3744a67-1003-421c-faf0-1209cf4b13ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([2, 3, 4, 5, 6])\n",
            "tensor([[ 0,  0,  0,  0,  0],\n",
            "        [ 2,  3,  4,  5,  6],\n",
            "        [ 4,  6,  8, 10, 12],\n",
            "        [ 6,  9, 12, 15, 18]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar dot product\n",
        "\n",
        "a = torch.arange(12).reshape(4, 3)\n",
        "b = torch.arange(6).reshape(3, 2)\n",
        "prod = torch.einsum('ij, jk ->', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkCFAJy1ulxb",
        "outputId": "77f7ac61-bdbb-4dd3-98a3-2edab5a4f7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "tensor(362)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hadamard product\n",
        "\n",
        "a = torch.arange(8).reshape(2, 4)\n",
        "b = torch.arange(4, 12).reshape(2, 4)\n",
        "prod = torch.einsum('ij, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psiMGjQOvCQ-",
        "outputId": "a6a8ba93-7a84-474d-aa53-eb9813ca3292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  5, 12, 21],\n",
            "        [32, 45, 60, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch matrix multiplication\n",
        "\n",
        "a = torch.randn(5, 3, 2)\n",
        "b = torch.randn(5, 2, 4)\n",
        "batch_mult = torch.einsum('bij, bjk -> bik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(batch_mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpt4m9eHvuJv",
        "outputId": "22a25565-5b42-4b18-fe7d-2b62be292450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.4553e+00, -1.7111e-01],\n",
            "         [ 4.0565e-01, -8.3465e-01],\n",
            "         [-4.7875e-01,  1.2393e+00]],\n",
            "\n",
            "        [[-1.4233e-01, -5.5644e-02],\n",
            "         [ 6.4517e-01, -2.4985e-01],\n",
            "         [ 2.8128e+00,  4.4208e-01]],\n",
            "\n",
            "        [[-5.9963e-01,  3.3907e-02],\n",
            "         [ 9.6385e-02, -4.1245e-01],\n",
            "         [-1.9093e-01, -2.0003e-01]],\n",
            "\n",
            "        [[ 8.7891e-01, -8.6112e-01],\n",
            "         [ 8.6214e-01,  1.0268e-03],\n",
            "         [ 5.1808e-01,  1.8051e-01]],\n",
            "\n",
            "        [[ 2.1406e-01, -1.5639e-01],\n",
            "         [-5.1803e-01,  2.9477e-01],\n",
            "         [-7.8507e-01, -8.9058e-01]]])\n",
            "tensor([[[ 0.0746,  1.0408,  0.5979, -0.5060],\n",
            "         [ 0.1247, -0.4264, -0.2611,  0.7767]],\n",
            "\n",
            "        [[-0.3301, -0.5288,  0.0081,  1.6001],\n",
            "         [ 0.1628,  0.3661,  0.4332, -1.1243]],\n",
            "\n",
            "        [[-0.0876, -0.4243,  1.3762,  1.0380],\n",
            "         [-0.1134,  0.1387,  0.2034,  0.7833]],\n",
            "\n",
            "        [[ 0.6693, -0.0103,  1.8785,  0.9205],\n",
            "         [ 0.0119, -1.5305, -0.1146,  1.4296]],\n",
            "\n",
            "        [[-0.9847,  0.1808,  0.8950, -0.0280],\n",
            "         [-0.7902, -0.2542, -1.6202, -0.9523]]])\n",
            "tensor([[[-0.1299, -1.4417, -0.8255,  0.6035],\n",
            "         [-0.0738,  0.7781,  0.4604, -0.8536],\n",
            "         [ 0.1188, -1.0267, -0.6098,  1.2049]],\n",
            "\n",
            "        [[ 0.0379,  0.0549, -0.0253, -0.1652],\n",
            "         [-0.2536, -0.4326, -0.1031,  1.3133],\n",
            "         [-0.8564, -1.3254,  0.2142,  4.0038]],\n",
            "\n",
            "        [[ 0.0487,  0.2591, -0.8183, -0.5959],\n",
            "         [ 0.0383, -0.0981,  0.0488, -0.2230],\n",
            "         [ 0.0394,  0.0533, -0.3034, -0.3549]],\n",
            "\n",
            "        [[ 0.5780,  1.3089,  1.7498, -0.4220],\n",
            "         [ 0.5770, -0.0105,  1.6194,  0.7951],\n",
            "         [ 0.3489, -0.2816,  0.9525,  0.7350]],\n",
            "\n",
            "        [[-0.0872,  0.0785,  0.4450,  0.1429],\n",
            "         [ 0.2772, -0.1686, -0.9412, -0.2662],\n",
            "         [ 1.4768,  0.0844,  0.7402,  0.8701]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor reduction\n",
        "\n",
        "a = torch.randn(3, 3, 5, 4)\n",
        "b = torch.randn(5, 1, 3, 11, 5)\n",
        "reduction = torch.einsum('pqrs, tuqvr -> pstuv', [a, b])\n",
        "print(a.shape, b.shape, reduction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ryk_vs9wXDr",
        "outputId": "816e98f4-4265-41d5-84e6-48453325f2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 3, 5, 4]) torch.Size([5, 1, 3, 11, 5]) torch.Size([3, 4, 5, 1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "\n",
        "a = torch.arange(10).reshape(5, 2)\n",
        "transpose = torch.einsum('ij -> ji', [a])\n",
        "print(a)\n",
        "print(transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kefVaa4ZwiwM",
        "outputId": "7b77ee15-dc87-47b9-8361-269da0eb4136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7],\n",
            "        [8, 9]])\n",
            "tensor([[0, 2, 4, 6, 8],\n",
            "        [1, 3, 5, 7, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bilinear transformation\n",
        "\n",
        "a = torch.randn(2, 4)\n",
        "b = torch.randn(3, 4, 4)\n",
        "c = torch.randn(2, 4)\n",
        "bilinear = torch.einsum('ik, jkl, il -> ij', [a, b, c])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(bilinear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBDN3S0Owv1r",
        "outputId": "628a028d-107f-42fb-be37-5bdbf5a1c9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0684, -1.5061, -0.9277, -2.0462],\n",
            "        [ 1.0035,  0.9128, -0.3480, -0.0150]])\n",
            "tensor([[[ 0.6079,  0.8268,  0.6350, -1.1869],\n",
            "         [-0.1083,  0.9952, -0.6336, -0.6504],\n",
            "         [-1.2705, -1.8204,  0.7749, -0.4700],\n",
            "         [ 2.0109,  1.3872, -1.0316, -1.0610]],\n",
            "\n",
            "        [[-0.9354,  1.1307, -0.5839,  2.0572],\n",
            "         [ 0.3872, -0.0847,  1.9612,  0.4865],\n",
            "         [ 0.1876,  0.3049,  0.0899, -1.5961],\n",
            "         [-0.1527,  1.5999, -0.9913, -0.3779]],\n",
            "\n",
            "        [[ 0.5941,  0.2433,  1.8852,  0.2115],\n",
            "         [ 1.2232, -1.0056, -0.5936, -0.8168],\n",
            "         [-0.9382, -0.3067, -0.0343, -0.4532],\n",
            "         [ 0.1750, -0.5382,  0.4577,  0.5255]]])\n",
            "tensor([[ 1.5155, -1.5626,  0.3557,  0.3391],\n",
            "        [-0.2585, -1.2897, -1.3806, -1.0695]])\n",
            "tensor([[ 1.4023,  1.9620, -5.0075],\n",
            "        [-1.2839, -5.9513, -1.2662]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention\n",
        "\n",
        "def random_tensors(shape, num=1, requires_grad=False):\n",
        "  tensors = [torch.randn(shape, requires_grad=requires_grad) for i in range(0, num)]\n",
        "  return tensors[0] if num == 1 else tensors\n",
        "\n",
        "# Parameters\n",
        "# [hidden_dimension]\n",
        "bM, br, w = random_tensors([6], num=3, requires_grad=True)\n",
        "# [hidden_dimension x hidden_dimension]\n",
        "WY, Wh, Wr, Wt = random_tensors([6, 6], num=4, requires_grad=True)\n",
        "\n",
        "def attention(Y, ht, rt1):\n",
        "  # [batch_size x hidden_dimension] \n",
        "  tmp = torch.einsum('ik, kl -> il', [ht, Wh]) + torch.einsum('ik, kl -> il', [rt1, Wr])\n",
        "\n",
        "  Mt = torch.tanh(torch.einsum('ijk, kl -> ijl', [Y, WY]) + tmp.unsqueeze(1).expand_as(Y) + bM)\n",
        "  \n",
        "  # [batch_size x sequence_length]\n",
        "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w])) \n",
        "  \n",
        "  # [batch_size x hidden_dimension]\n",
        "  rt = torch.einsum('ijk, ij -> ik', [Y, at]) + torch.tanh(torch.einsum('ij, jk -> ik', [rt1, Wt]) + br)\n",
        "  \n",
        "  return rt, at\n",
        "\n",
        "# Inputs - [batch_size x sequence_length x hidden_dimension]\n",
        "Y = torch.randn(3,5,6)\n",
        "# [batch_size x hidden_dimension]\n",
        "ht, rt1 = random_tensors([3, 6], num=2)\n",
        "\n",
        "rt, at = attention(Y, ht, rt1)\n",
        "\n",
        "print(at)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6CrpIkcw4zZ",
        "outputId": "5d20e2e4-fc05-4a34-af83-90792c16d16d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3064, 0.1261, 0.1296, 0.3212, 0.1166],\n",
            "        [0.1670, 0.1798, 0.1275, 0.2898, 0.2359],\n",
            "        [0.1555, 0.1757, 0.0619, 0.3698, 0.2371]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-ab904282b68c>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treeqn\n",
        "\n",
        "def transition(zl):\n",
        "  # [batch_size x num_actions x hidden_dimension]\n",
        "  return zl.unsqueeze(1) + torch.tanh(torch.einsum('bk, aki -> bai', [zl, W]) + b)\n",
        "\n",
        "# Inputs - [batch_size x hidden_dimension]\n",
        "zl = torch.randn(2, 3)\n",
        "# Parameters - [num_actions x hidden_dimension]\n",
        "b = torch.randn(5, 3)\n",
        "# Actions - [num_actions x hidden_dimension x hidden_dimension]\n",
        "W = torch.randn(5, 3, 3)\n",
        "\n",
        "transition(zl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHrBxGoUw5hm",
        "outputId": "ae72c6ec-55e6-4793-a66c-bd5fc8334751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9229, -0.2503, -0.4214],\n",
              "         [-0.7416, -0.7648, -0.6006],\n",
              "         [-1.9246, -1.0549, -0.6626],\n",
              "         [-0.1298, -1.0461, -0.2297],\n",
              "         [-1.2603,  0.4822,  1.2827]],\n",
              "\n",
              "        [[ 1.6660,  0.5844,  1.8875],\n",
              "         [ 0.2896, -1.2155,  0.7097],\n",
              "         [ 0.3233,  0.3691,  1.7026],\n",
              "         [ 0.4486, -1.3444,  2.2562],\n",
              "         [ 2.2118, -1.3579,  1.4453]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOd329uq5xLc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}