{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shernee/04_cmpe258/blob/main/Operations_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQjnqkIqqB9L"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar vector multiplication\n",
        "\n",
        "a = torch.rand(1)\n",
        "b = torch.rand(5, 3)\n",
        "mult = torch.einsum('i, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtFaCWo7sxjW",
        "outputId": "35acaffe-1241-4f37-ccee-41c62d5f427d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2542])\n",
            "tensor([[0.9818, 0.1692, 0.2384],\n",
            "        [0.7258, 0.6678, 0.6200],\n",
            "        [0.7074, 0.5768, 0.5534],\n",
            "        [0.7542, 0.6208, 0.4449],\n",
            "        [0.1048, 0.2223, 0.6567]])\n",
            "tensor([[0.2496, 0.0430, 0.0606],\n",
            "        [0.1845, 0.1697, 0.1576],\n",
            "        [0.1798, 0.1466, 0.1406],\n",
            "        [0.1917, 0.1578, 0.1131],\n",
            "        [0.0266, 0.0565, 0.1669]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector vector multiplication\n",
        "\n",
        "a = torch.rand(2, 5)\n",
        "b = torch.rand(5, 3)\n",
        "mult = torch.einsum('ij, jk -> ik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR0oA9l5tO0a",
        "outputId": "d31855f1-4c97-437f-a2f1-b3626b72b846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6429, 0.4204, 0.1272, 0.5873, 0.0031],\n",
            "        [0.7863, 0.5485, 0.0711, 0.9759, 0.9929]])\n",
            "tensor([[0.3160, 0.9855, 0.1188],\n",
            "        [0.6517, 0.2639, 0.7850],\n",
            "        [0.6204, 0.6317, 0.0065],\n",
            "        [0.3744, 0.1599, 0.2280],\n",
            "        [0.1682, 0.0522, 0.4415]])\n",
            "tensor([[0.7764, 0.9188, 0.5424],\n",
            "        [1.1824, 1.1724, 1.1853]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer product\n",
        "\n",
        "a = torch.arange(4)\n",
        "b = torch.arange(3, 6)  \n",
        "prod = torch.einsum('i,j -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXP4fcRjuNi7",
        "outputId": "e5be5f1c-25f5-43e4-b1a2-df93e09bc401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([3, 4, 5])\n",
            "tensor([[ 0,  0,  0],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  8, 10],\n",
            "        [ 9, 12, 15]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar dot product\n",
        "\n",
        "a = torch.arange(9).reshape(3, 3)\n",
        "b = torch.arange(6).reshape(3, 2)\n",
        "prod = torch.einsum('ij, jk ->', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkCFAJy1ulxb",
        "outputId": "4edbfb9d-142c-4d22-a6e9-f11e89638660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "tensor(204)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hadamard product\n",
        "\n",
        "a = torch.arange(8).reshape(2, 4)\n",
        "b = torch.arange(4, 12).reshape(2, 4)\n",
        "prod = torch.einsum('ij, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psiMGjQOvCQ-",
        "outputId": "595fa92a-8656-4055-b8d5-2036db8cebc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  5, 12, 21],\n",
            "        [32, 45, 60, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch matrix multiplication\n",
        "\n",
        "a = torch.randn(3, 3, 5)\n",
        "b = torch.randn(3, 5, 2)\n",
        "batch_mult = torch.einsum('bij, bjk -> bik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(batch_mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpt4m9eHvuJv",
        "outputId": "370b8c2e-3a22-41a1-eb73-46497a1803c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.6773,  0.7815,  0.0976, -0.3376, -1.0016],\n",
            "         [-0.2147,  0.5441, -0.1041, -1.5888, -0.1477],\n",
            "         [ 0.4789,  0.1681,  0.2626,  0.1920,  1.5456]],\n",
            "\n",
            "        [[ 0.4644,  0.4793, -0.8845,  0.4871,  0.0896],\n",
            "         [ 0.1962, -1.5146, -0.0384, -1.5082,  2.0303],\n",
            "         [-0.1432, -0.8256,  2.1222, -0.7460,  1.7938]],\n",
            "\n",
            "        [[-2.4303, -0.3767, -1.2423,  1.7091, -0.2427],\n",
            "         [ 1.1554,  0.7634, -1.5851, -0.2582, -0.1536],\n",
            "         [ 0.2669, -0.1670, -1.0830,  0.7396,  1.6235]]])\n",
            "tensor([[[ 0.0491, -0.9551],\n",
            "         [ 1.1950, -1.3534],\n",
            "         [-0.3555, -0.5985],\n",
            "         [-0.4036,  0.3748],\n",
            "         [-0.2693, -1.0826]],\n",
            "\n",
            "        [[-0.4017, -0.1576],\n",
            "         [-1.5601,  0.5673],\n",
            "         [-1.0467,  1.2570],\n",
            "         [ 0.7197,  0.4947],\n",
            "         [-1.7960,  0.3878]],\n",
            "\n",
            "        [[-1.0549,  0.3017],\n",
            "         [ 0.3286,  1.7896],\n",
            "         [-0.3106,  0.0359],\n",
            "         [-0.3485, -0.6107],\n",
            "         [ 1.1762, -1.3009]]])\n",
            "tensor([[[ 1.2719,  0.4887],\n",
            "         [ 1.3576, -0.9046],\n",
            "         [-0.3627, -2.4433]],\n",
            "\n",
            "        [[ 0.1813, -0.6374],\n",
            "         [-2.4074, -0.8972],\n",
            "         [-4.6343,  2.5483]],\n",
            "\n",
            "        [[ 1.9447, -2.1802],\n",
            "         [-0.5663,  2.0154],\n",
            "         [ 1.6517, -2.8210]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor reduction\n",
        "\n",
        "a = torch.randn(2, 3, 5, 7)\n",
        "b = torch.randn(4, 1, 3, 11, 5)\n",
        "reduction = torch.einsum('pqrs, tuqvr -> pstuv', [a, b])\n",
        "print(a.shape, b.shape, reduction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ryk_vs9wXDr",
        "outputId": "a631b5c0-2630-4c82-edfb-b7d52824eb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5, 7]) torch.Size([4, 1, 3, 11, 5]) torch.Size([2, 7, 4, 1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "\n",
        "a = torch.arange(8).reshape(4, 2)\n",
        "transpose = torch.einsum('ij -> ji', [a])\n",
        "print(a)\n",
        "print(transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kefVaa4ZwiwM",
        "outputId": "73c99566-3759-4983-d04f-c4dd40760384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7]])\n",
            "tensor([[0, 2, 4, 6],\n",
            "        [1, 3, 5, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bilinear transformation\n",
        "\n",
        "a = torch.randn(2, 3)\n",
        "b = torch.randn(3, 3, 4)\n",
        "c = torch.randn(2, 4)\n",
        "bilinear = torch.einsum('ik, jkl, il -> ij', [a, b, c])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(bilinear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBDN3S0Owv1r",
        "outputId": "549f71b4-0193-4f24-d13a-2cf3a130b339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0194, -1.0325,  1.1552],\n",
            "        [ 1.7109,  0.6803, -0.2855]])\n",
            "tensor([[[-6.1467e-01,  1.1213e+00, -8.7369e-01,  7.0915e-01],\n",
            "         [-2.5071e+00,  6.4044e-01, -2.8877e-01, -6.7373e-01],\n",
            "         [-2.8574e-01,  2.3551e+00,  6.9576e-01,  1.7975e-01]],\n",
            "\n",
            "        [[ 7.8964e-01,  2.2677e-01,  8.7683e-03,  1.6208e-01],\n",
            "         [-1.0357e+00,  9.0935e-01, -2.6189e-01,  1.0951e+00],\n",
            "         [ 6.7263e-01, -3.5130e-01,  9.0431e-01, -7.5851e-01]],\n",
            "\n",
            "        [[ 1.2006e+00, -8.0647e-01,  1.0881e+00,  1.8557e-03],\n",
            "         [ 1.5820e+00, -6.4618e-01, -2.9748e-01,  8.3277e-01],\n",
            "         [ 1.0650e+00,  3.0839e-01, -8.7738e-01,  1.1741e+00]]])\n",
            "tensor([[ 0.8010, -1.1297,  0.8869, -0.6142],\n",
            "        [ 1.2567, -1.2474, -0.3489,  1.5471]])\n",
            "tensor([[-3.1221,  5.6872,  0.4812],\n",
            "        [-3.7124,  1.2538,  5.6274]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention\n",
        "\n",
        "def random_tensors(shape, num=1, requires_grad=False):\n",
        "  tensors = [torch.randn(shape, requires_grad=requires_grad) for i in range(0, num)]\n",
        "  return tensors[0] if num == 1 else tensors\n",
        "\n",
        "# Parameters\n",
        "# [hidden_dimension]\n",
        "bM, br, w = random_tensors([7], num=3, requires_grad=True)\n",
        "# [hidden_dimension x hidden_dimension]\n",
        "WY, Wh, Wr, Wt = random_tensors([7, 7], num=4, requires_grad=True)\n",
        "\n",
        "def attention(Y, ht, rt1):\n",
        "  # [batch_size x hidden_dimension] \n",
        "  tmp = torch.einsum('ik, kl -> il', [ht, Wh]) + torch.einsum('ik, kl -> il', [rt1, Wr])\n",
        "\n",
        "  Mt = torch.tanh(torch.einsum('ijk, kl -> ijl', [Y, WY]) + tmp.unsqueeze(1).expand_as(Y) + bM)\n",
        "  \n",
        "  # [batch_size x sequence_length]\n",
        "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w])) \n",
        "  \n",
        "  # [batch_size x hidden_dimension]\n",
        "  rt = torch.einsum('ijk, ij -> ik', [Y, at]) + torch.tanh(torch.einsum('ij, jk -> ik', [rt1, Wt]) + br)\n",
        "  \n",
        "  return rt, at\n",
        "\n",
        "# Inputs - [batch_size x sequence_length x hidden_dimension]\n",
        "Y = torch.randn(3,5,7)\n",
        "# [batch_size x hidden_dimension]\n",
        "ht, rt1 = random_tensors([3, 7], num=2)\n",
        "\n",
        "rt, at = attention(Y, ht, rt1)\n",
        "\n",
        "print(at)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6CrpIkcw4zZ",
        "outputId": "385b8e9d-0015-4876-fc61-9a5764d7a6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1494, 0.3332, 0.3192, 0.1044, 0.0939],\n",
            "        [0.0530, 0.5588, 0.2151, 0.0731, 0.1000],\n",
            "        [0.2654, 0.0522, 0.3481, 0.2986, 0.0356]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-0f495568e4dc>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treeqn\n",
        "\n",
        "def transition(zl):\n",
        "  # [batch_size x num_actions x hidden_dimension]\n",
        "  return zl.unsqueeze(1) + torch.tanh(torch.einsum('bk, aki -> bai', [zl, W]) + b)\n",
        "\n",
        "# Inputs - [batch_size x hidden_dimension]\n",
        "zl = torch.randn(2, 3)\n",
        "# Parameters - [num_actions x hidden_dimension]\n",
        "b = torch.randn(5, 3)\n",
        "# Actions - [num_actions x hidden_dimension x hidden_dimension]\n",
        "W = torch.randn(5, 3, 3)\n",
        "\n",
        "transition(zl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHrBxGoUw5hm",
        "outputId": "12539a35-ae2c-4539-bdfd-54593a303f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7924, -0.5440,  1.1019],\n",
              "         [-0.7051, -0.2637, -0.3537],\n",
              "         [-0.8080,  1.0011,  1.4171],\n",
              "         [-0.2296, -0.1790,  1.2798],\n",
              "         [ 1.0797,  0.5839, -0.2840]],\n",
              "\n",
              "        [[ 0.0376, -1.3244,  0.5081],\n",
              "         [-0.2335, -1.2459,  0.0876],\n",
              "         [-1.0806, -0.3098,  1.3159],\n",
              "         [-0.1106, -0.8778, -0.0471],\n",
              "         [ 0.5811,  0.4377, -0.5074]]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOd329uq5xLc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}