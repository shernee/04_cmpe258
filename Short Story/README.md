## Short story requirement for CPME258 DEEP LEARNING

### How Chain-of-thought prompting is used to elicit reasoning in Large Language Models

‘Large’ Language Models own the capability of processing and understanding large amounts of natural language data and are used across a range of natural language tasks such as text summarization, sentiment analysis, topic classification, language translation, autocompletion to name a few.

While most of the tasks performed by these models benefit from scaling, tasks such as arithmetic, commonsense and symbolic reasoning fail to see performance improvements on scaling the model. This leads us to explore the method of ‘chain-of-thought prompting’ wherein generating a series of intermediate reasoning steps or chain-of-thought improves the complex reasoning ability of LLM’s.

This paper talks about how Chain of thought prompting exceeds previous SOTA and standard prompting on reasoning tasks by observing how various models (with varying scale) perform on different benchmark problem sets (across tasks). 

The short story has been posted on [Medium](https://medium.com/@neelearning93/using-chain-of-thought-prompting-to-elicit-reasoning-in-large-language-models-b0fd970bb338), the corresponding slide-deck is uploaded on [Slideshare](https://www.slideshare.net/NeethaSherra1/chainofthought-promptingpptx) and the video is posted on [Youtube](https://youtu.be/fKVhJF42BK8)